Question Answer


WHY REDIS

Schnelle Zugriffszeiten: Redis speichert alle Daten im Arbeitsspeicher (RAM), wodurch sie besonders schnell abrufbar sind.

Hohe Skalierbarkeit: Redis unterstützt horizontale Skalierung, indem mehrere Server hinzugefügt werden können, um die Kapazität zu erhöhen.

Unterstützung für verschiedene Datentypen: Redis unterstützt verschiedene Datentypen, wie z.B. Listen, Sets und Hashes, die für die Verwendung in verschiedenen Anwendungen nützlich sein können.

Unterstützung für Pub/Sub: Redis bietet eine Funktionalität zum Publizieren und Abonnieren von Nachrichten (Pub/Sub), die für die Verwendung als Message Broker nützlich sein kann.

Persistente Speicherung: Redis kann so konfiguriert werden, dass Daten persistent gespeichert werden, auch wenn der Server neu gestartet wird.


WHY MONGO DB 


Unterstützung für unstrukturierte Daten: MongoDB speichert Daten in einem dokumentenorientierten Format, das es ermöglicht, Daten ohne festgelegte Schema zu speichern. Diese Flexibilität kann nützlich sein, wenn sich die Struktur von Daten im Laufe der Zeit ändert oder wenn die Daten unterschiedliche Strukturen aufweisen.

Schnelle Zugriffszeiten: MongoDB verwendet ein Indexing-System, das es ermöglicht, schnellen Zugriff auf Daten zu erhalten.

Hohe Skalierbarkeit: MongoDB unterstützt horizontale Skalierung, indem mehrere Server hinzugefügt werden können, um die Kapazität zu erhöhen.

Unterstützung für mehrere Sprachen: MongoDB bietet native Unterstützung für eine Vielzahl von Programmiersprachen, wie z.B. Java, Python, C++ und viele mehr.

Unterstützung für Replikation und Hochverfügbarkeit: MongoDB unterstützt die Replikation von Daten auf mehrere Server, um die Verfügbarkeit und die Redundanz von Daten zu erhöhen.


WHY SPARK 

Hohe Verarbeitungsleistung: Spark bietet hohe Verarbeitungsleistung und ist in der Lage, große Datenmengen in Echtzeit zu verarbeiten.

Unterstützung für mehrere Sprachen: Spark unterstützt eine Vielzahl von Programmiersprachen, wie z.B. Java, Python, Scala und R, was es für viele Entwickler attraktiv macht.

Integration mit anderen Tools und Frameworks: Spark kann in Verbindung mit and


WHY KAFKA 
real-time data processing: Kafka events can be processed in real-time, which makes them useful for applications that need to respond to incoming data as soon as it is available.

Scalability: Kafka can handle high volumes of data with low latency, making it suitable for handling large amounts of events.

Integration: Kafka events can be easily integrated with other systems and tools, such as Apache Hadoop, Apache Flink, and Apache Spark, making them a useful component in a larger data processing pipeline.

Loose coupling: Kafka events allow different systems and applications to share data without being tightly coupled, which can make it easier to add or remove components from the pipeline without affecting the other systems.

Async communication: Kafka events can be used for asynchronous communication between systems, which means that the sender and receiver don't need to be available at the same time.











DataLakes



More than 80% of companies considerunstructured data to be important or critical to their analyses.
70% of organizations rate data warehouse technology as important or a high investment priority
Best-in-Class companies are twice as likely to have strong data governance procedures in place
Leading companies are 70% more likely to be satisfied with the accessibility of organizational data.







Data Lakes ersetzen :

Vielmehr kann ein Datalake als Ergänzung zu bestehenden Systemen dienen und dazu beitragen, 
die Effizienz und Flexibilität von Datenverarbeitung und -analyse zu verbessern. 
In vielen Fällen werden Datalakes verwendet, um Daten aus verschiedenen Quellen zu integrieren und zu speichern, 
um dann von anderen Systemen und Anwendungen genutzt zu werden.





Welche 3 Metriken korrelieren am meisten mit einer guten Data Lake-Performance, bzw Ergebnissen im Unternehmen

Nutzungsrate: Die Nutzungsrate gibt an, wie oft der Data Lake von verschiedenen Teams und Anwendungen im Unternehmen genutzt wird. 
Eine hohe Nutzungsrate kann darauf hinweisen, dass der Data Lake von großem Nutzen für das Unternehmen ist und effektiv genutzt wird.

Durchsatz: Der Durchsatz gibt an, wie viele Daten innerhalb eines bestimmten Zeitraums in den Data Lake geladen und verarbeitet werden. 
Ein hoher Durchsatz kann darauf hinweisen, dass der Data Lake in der Lage ist, große Mengen an Daten effektiv zu verarbeiten und zu speichern.

Verfügbarkeit: Die Verfügbarkeit gibt an, wie zuverlässig der Data Lake ist und wie häufig er für Benutzer und Anwendungen verfügbar ist. 
Eine hohe Verfügbarkeit ist wichtig, um sicherzustellen, dass der Data Lake für das Unternehmen zu jeder Zeit zugänglich ist und dass Benutzer 
und Anwendungen auf Daten zugreifen können, wenn sie benötigt werden.